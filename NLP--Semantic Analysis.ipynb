{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-----\n",
    "# NLP: Semantic Analysis\n",
    "In this problem, we explore semantic analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "7f833e774b49cba6ab19112f1806dc74",
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import time\n",
    "import numpy as np\n",
    "import gensim\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "from nose.tools import (\n",
    "    assert_equal,\n",
    "    assert_is_instance,\n",
    "    assert_almost_equal,\n",
    "    assert_true\n",
    "    )\n",
    "\n",
    "from numpy.testing import assert_array_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "# Wordnet\n",
    "We use the Wordnet synonym rings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "301a30c7a5990d75efe00f0ac5a0fe80",
     "grade": false,
     "grade_id": "wn",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find how many entries a word has in the wordnet synset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "268af5336234bd7230849335c96da7d7",
     "grade": false,
     "grade_id": "e",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def find_number_of_entries(word):\n",
    "    '''\n",
    "    Finds the number of entries in the wordnet synset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    word: A string.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    An int.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    the_synsets = wn.synsets(word)\n",
    "    result = len(the_synsets)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "e94ac7b7795fa90ccf6c4fe2368c79b8",
     "grade": false,
     "grade_id": "print_e1",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 total entries in synonym ring for love. \n"
     ]
    }
   ],
   "source": [
    "the_word = 'love'\n",
    "n_entries = find_number_of_entries(the_word)\n",
    "print('{0} total entries in synonym ring for {1}. '.format(n_entries, the_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "6044f7ab43772f05f37d873265e160bb",
     "grade": false,
     "grade_id": "print_e2",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 total entries in synonym ring for live. \n"
     ]
    }
   ],
   "source": [
    "the_word = 'live'\n",
    "n_entries = find_number_of_entries(the_word)\n",
    "print('{0} total entries in synonym ring for {1}. '.format(n_entries, the_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "14f10ebe2c8f1077154e2cce106f208f",
     "grade": true,
     "grade_id": "test_e",
     "locked": true,
     "points": 8,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(find_number_of_entries('love'), int)\n",
    "assert_equal(find_number_of_entries('love'), 10)\n",
    "assert_equal(find_number_of_entries('live'), 19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Similarities\n",
    "- Compute the path similarity for the input words. \n",
    "- Use the first noun synset (with number 01) for each word. \n",
    "- You could assume all input words have at least one noun synset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "7e728179c6c8e2be3e65198fa0aceff3",
     "grade": false,
     "grade_id": "ps",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_path_similarity(word1, word2):\n",
    "    '''\n",
    "    Computes the path similarity between word1 and word1.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    word1: A string.\n",
    "    word2: A string.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A float.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    word1_ = wn.synset(word1 + \".n.01\")\n",
    "    word2_ = wn.synset(word2 + \".n.01\")\n",
    "    result = wn.path_similarity(word1_, word2_)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "930b0c842a9447d0812150e2d28bd5d4",
     "grade": false,
     "grade_id": "print_ps",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path Similarity:\n",
      "----------------------------------------\n",
      "excess to surplus: 1.000\n",
      "trade to economy: 0.100\n",
      "mean to average: 0.500\n",
      "mean to average: 0.333\n",
      "excess to excess: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Now we print similarity measures.\n",
    "fmt_str = '{1} to {2}: {0:4.3f}'\n",
    "\n",
    "print('Path Similarity:')\n",
    "print(40*'-')\n",
    "print(fmt_str.format(get_path_similarity('excess', 'surplus'), 'excess', 'surplus'))\n",
    "print(fmt_str.format(get_path_similarity('trade', 'economy'), 'trade', 'economy'))\n",
    "print(fmt_str.format(get_path_similarity('mean', 'average'), 'mean', 'average'))\n",
    "print(fmt_str.format(get_path_similarity('import', 'export'), 'mean', 'average'))\n",
    "print(fmt_str.format(get_path_similarity('excess', 'excess'), 'excess', 'excess'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "2bb6c39ea2c66473a3c6444e2069368b",
     "grade": true,
     "grade_id": "test_ps",
     "locked": true,
     "points": 8,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(get_path_similarity('excess', 'surplus'), float)\n",
    "assert_almost_equal(get_path_similarity('excess', 'surplus'), 1.0)\n",
    "assert_almost_equal(get_path_similarity('trade', 'economy'), 0.1)\n",
    "assert_almost_equal(get_path_similarity('mean', 'average'), 0.5)\n",
    "assert_almost_equal(get_path_similarity('import', 'export'), 0.3333333333333333)\n",
    "assert_almost_equal(get_path_similarity('excess', 'excess'), 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "# Word2Vec\n",
    "In the second half of this problem, we use the NLTK reuters corpus to build a word2vec model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "922c61e319a7630a87c63d3193f17741",
     "grade": false,
     "grade_id": "reuters",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters\n",
    "sentences = reuters.sents()[:20000] # use a sample size smaller than corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec model\n",
    "- Build a Word2Vec model from sentences in the corpus.\n",
    "- Set the maximum distance between the current and predicted word within a sentence to 10.\n",
    "- Ignore all words with total frequency lower than 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "7341c9e49e00c926d358d5609ba4af6b",
     "grade": false,
     "grade_id": "model",
     "locked": false,
     "points": 7,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_model(sentences):\n",
    "    '''\n",
    "    Builds a Word2Vec model from sentences in corpus.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sentences: A list of lists(sentences); each sentence is a list of strings(words).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A Word2Vec instance.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    model = gensim.models.Word2Vec(sentences, window=10, min_count=6)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell would take about 30 seconds to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "5fa519b3ac0b1171ef27b0491680c6b9",
     "grade": false,
     "grade_id": "get_model",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.884390000000003 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.clock()\n",
    "model = get_model(sentences)\n",
    "print(time.clock() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "7ad769fd1b250b71620c2ab6cdbd6a66",
     "grade": true,
     "grade_id": "test_model",
     "locked": true,
     "points": 8,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(model, gensim.models.Word2Vec)\n",
    "assert_equal(model.window, 10)\n",
    "assert_equal(model.min_count, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity\n",
    "Compute Cosine Similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "5a31cc029b9b189a7287df6695a05fa7",
     "grade": false,
     "grade_id": "cs",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_cosine_similarity(model, word1, word2):\n",
    "    '''\n",
    "    Computes cosine similarity between \"word1\" and \"word2\" using a Word2Vec model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model: A gensim.Word2Vec model.\n",
    "    word1: A string.\n",
    "    word2: A string.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A float.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    similarity = model.similarity(word1, word2)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "59a4ffb7d6cc3af6b68f30291c8de540",
     "grade": false,
     "grade_id": "print_cs",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity:\n",
      "----------------------------------------\n",
      "excess to surplus: 0.453\n",
      "trade to economy: 0.808\n",
      "mean to average: 0.172\n",
      "mean to average: 0.843\n",
      "excess to excess: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Now we print similarity measures.\n",
    "fmt_str = '{1} to {2}: {0:4.3f}'\n",
    "\n",
    "print('Cosine Similarity:')\n",
    "print(40*'-')\n",
    "print(fmt_str.format(get_cosine_similarity(model, 'excess', 'surplus'), 'excess', 'surplus'))\n",
    "print(fmt_str.format(get_cosine_similarity(model, 'trade', 'economy'), 'trade', 'economy'))\n",
    "print(fmt_str.format(get_cosine_similarity(model, 'mean', 'average'), 'mean', 'average'))\n",
    "print(fmt_str.format(get_cosine_similarity(model, 'import', 'export'), 'mean', 'average'))\n",
    "print(fmt_str.format(get_cosine_similarity(model, 'excess', 'excess'), 'excess', 'excess'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "4aa6f26dba30219639541378398aa326",
     "grade": true,
     "grade_id": "test_cs",
     "locked": true,
     "points": 8,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(get_cosine_similarity(model, 'excess', 'surplus'), float)\n",
    "assert_almost_equal(get_cosine_similarity(model, 'excess', 'surplus'), model.similarity('excess', 'surplus'))\n",
    "assert_almost_equal(get_cosine_similarity(model, 'trade', 'economy'), model.similarity('trade', 'economy'))\n",
    "assert_almost_equal(get_cosine_similarity(model, 'mean', 'average'), model.similarity('mean', 'average'))\n",
    "assert_almost_equal(get_cosine_similarity(model, 'import', 'export'), model.similarity('import', 'export'))\n",
    "assert_almost_equal(get_cosine_similarity(model, 'excess', 'excess'), 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most similar words\n",
    "Find the top 5 most similar words, where \"price\", \"economy\", and \"trade\" contribute positively towards the similarity, and \"law\" and \"legal\" contribute negatively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "eca3bba6595875eb5a0264fdf2981520",
     "grade": false,
     "grade_id": "sw",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def find_most_similar_words(model):\n",
    "    '''\n",
    "    Find the top 5 most similar words,\n",
    "    where \"price\", \"economy\", and \"trade\" contribute positively towards the similarity,\n",
    "    and \"law\" and \"legal\" contribute negatively.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model: A gensim.Word2Vec model.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A list of tuples (word, similarty).\n",
    "    word: A string.\n",
    "    similarity: A float.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    result = model.most_similar(positive=['price', 'economy','trade'], negative=['law','legal'], topn=5)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "53f1744adf051f6f8189035db5ef5786",
     "grade": false,
     "grade_id": "print_sw",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word          : Cosine Similarity\n",
      "----------------------------------------\n",
      "rise          :  0.710\n",
      "current       :  0.707\n",
      "fall          :  0.705\n",
      "level         :  0.697\n",
      "prices        :  0.689\n"
     ]
    }
   ],
   "source": [
    "print('{0:14s}: {1}'.format('Word', 'Cosine Similarity'))\n",
    "print(40*'-')\n",
    "for val in find_most_similar_words(model):\n",
    "    print('{0:14s}: {1:6.3f}'.format(val[0], val[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "e8598a4215548a15e99b7f0d02d76dce",
     "grade": true,
     "grade_id": "test_sw",
     "locked": true,
     "points": 8,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(find_most_similar_words(model), list)\n",
    "assert_true(all(isinstance(t[0], str) for t in find_most_similar_words(model)))\n",
    "assert_true(all(isinstance(t[1], float) for t in find_most_similar_words(model)))\n",
    "assert_equal(len(find_most_similar_words(model)), 5)\n",
    "words = [t[0] for t in model.most_similar(positive=['price', 'economy', 'trade'], negative=['law', 'legal'], topn=5)]\n",
    "similarities = [t[1] for t in model.most_similar(positive=['price', 'economy', 'trade'], negative=['law', 'legal'], topn=5)]\n",
    "assert_equal([t[0] for t in find_most_similar_words(model)], words)\n",
    "assert_almost_equal(find_most_similar_words(model)[0][1], similarities[0])\n",
    "assert_almost_equal(find_most_similar_words(model)[1][1], similarities[1])\n",
    "assert_almost_equal(find_most_similar_words(model)[2][1], similarities[2])\n",
    "assert_almost_equal(find_most_similar_words(model)[3][1], similarities[3])\n",
    "assert_almost_equal(find_most_similar_words(model)[4][1], similarities[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
